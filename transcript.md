# Introduction

### Welcome to country

I wish to begin by acknowledging the Wurundjeri people, the traditional owners of the land on which we are gathered today. We pay our respects to the local people for allowing us to have our gathering on their land and to their Elders; past, present and future.

Thanks everyone for coming today, and a huge thanks to Ben and Rick for convening an event as amazing as Buzzconf Nights.

### Audio impaired

If there are any hearing impaired members of the audience, let me know and I can provide you with a transcript of the presentation to follow along to.

### License

This presentation is licensed under Creative Commons universal - you're free to share and re-use this presentation. Please use it to do awesome things.


# Notes
Gartner  from graphical UI to environmental UI - using the environment to control systems
Drivers for change in user interfaces - computing has moved away from the desktop and into mobile devices and wearables - we're no longer at our desks - but the GUI remains, albeit with a touch interface on phones.
Touch interface also seen on wearables - for instance, you tap your fitbit to get information displayed.
What about the Pebble - with the pebble it's still the push of a button to control the interface - but the content is actually driven from a second devices
This could be a good segue into Machine 2 Machine interface - one machine controlling another in response to environmental stimuli.

Adoption - many different people are adopting technology - different languages, different cultural context and different physical abilities - for intance an aging population, who may have difficulty with text, or medical conditions such as stroke which may impair speech.

Sophistication - people are becoming more accepting of technology and are adopting it in many different use cases - they *expect* more user interfaces.

Is this complexity a bad thing? Interfaces are interaction languages - with a syntax and expected response - if I double click this element, then it should respond in this way. Is the explosion of different ways to interface with systems becoming a burden - a cognitive burden? Or will our brains be elastic and just attune or adjust to the propagation of so many different interfaces? Do we need to stop or deprecate some of the interfaces we have to make room?

Evolution of the desktop interface - touch gestures - pinch, zoom, twist
Use of scribes, pens, surface 3 - perhaps our fingers are too fat.
We're still a little way away from the Minority report style gesture control - but with things like the Kinect it's likely to be here soon.

For all the talk of gesture control, tablet control etc, there's still research and development going on established devices - such as keyboards.

Source Citation   (MLA 7th Edition)
Ishii, Hiroshi. "The tangible user interface and its evolution." Communications of the ACM June 2008: 32+. Expanded Academic ASAP. Web. 4 Aug. 2016.
URL
http://ezproxy.deakin.edu.au/login?url=http://go.galegroup.com/ps/i.do?id=GALE%7CA180723121&v=2.1&u=deakin&it=r&p=EAIM&sw=w&asid=fb21fefd9560c521ad947e3f566a958c


Koskela - *pattern control* versus *instant control*
context aware functions - context menus - but now we're seein physical context - environmental UIs.

What happens when environmental UIs and emotional UIs collide?
Conversational UIs that can tell when people are pissed off?
Will the colour of digital signage change to something more soothing?

Trust in the user interface - what happens then the user interface is not just around us, but inside us?

Examples of kickstarter projects for keyboards

https://www.kickstarter.com/projects/keyboardio/the-model-01-an-heirloom-grade-keyboard-for-seriou

https://www.kickstarter.com/projects/1229573443/das-keyboard-5q-the-cloud-connected-keyboard

From Gartner - "The UI shifts from GUIs attached to individual devices to an "environmental user interface," acting as a contextual user access and information delivery engine across multiple devices." - creating a proactive UI framework for the environment

So what are the implications for this for practitioners
* you don't just need a UI framework for something like web or mobile interfaces - your UI framework needs to be an *environmental interaction* framework that has seamless, familiar interfaces for things like touch, gesture control, conversational UI and digital signage, emotional response etc - it's an interaction guide, not a web user interface guide. How is this tied to branding? How many company style guides are still print based, with a concession to web user interfaces? Style guides will become interaction guides - when a sound or gesture or even conversational UI is associated with a brand.

OK Google - Siri - they are part of larger brands.

Just like brands - interaction families will have a personality or flavour - for instance a corporate with a focus on efficiency may have an interaction family which is spartan, quick, with a minimum of movement or sound. A more social or fun brand may have an interaction family which focuses on lots of verbal interaction or fun gestures.

Location awareness and gaze tracking are needed for speech recognition - Microsoft paper - early 2000s

Ninja sphere - gesture control and swiping
Cognitoys Dino - voice recognition - toy interface design
Wiimote - take in the Wiimote to show off

Haber et al - intimate space, personal space, social space, public space - does the user interface know which one it's operating in?

http://developer.affectiva.com/ - emotional API







# Overview

# References
